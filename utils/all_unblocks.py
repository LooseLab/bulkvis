import h5py
import pandas as pd
import numpy as np
from argparse import ArgumentParser
from tqdm import tqdm
import sys


def main():
    args = get_args()
    # open bulkfile
    bulkfile = h5py.File(args.bulk_file, "r")
    # get bulkfile sample_frequency
    sf = int(bulkfile["UniqueGlobalKey"]["context_tags"].attrs["sample_frequency"].decode('utf8'))
    # get bulkfile run_id
    run_id = bulkfile["UniqueGlobalKey"]["tracking_id"].attrs["run_id"].decode('utf8')
    path = bulkfile['StateData']
    state_fields = ['acquisition_raw_index', 'summary_state']
    labels_df_list = []
    ch_count = 1
    print("Run ID:")
    print(run_id)
    print("Collecting state data:")
    # collect all unblocks across all channels with start time
    for channel in path:
        state_path = path[channel]['States']
        while ch_count == 1:
            dtypes = get_dtypes(state_path, 'summary_state')
            ch_count += 1
        # create list of DataFrames
        labels_df_list.append(get_df(state_path, state_fields))

    # concat all df together
    events_df = pd.concat(labels_df_list)
    # slim df to just 'unblocking'
    events_df = events_df[events_df['summary_state'] == dtypes[args.event]]
    events_df['acquisition_raw_index'] = events_df['acquisition_raw_index'] / sf
    # open summary files
    ss_fields = ['read_id', 'run_id', 'start_time']

    singles_out = pd.DataFrame({'Singles': parse_summary(args.singles, ss_fields, events_df, run_id, args.time)})
    singles_out.to_csv(args.singles_out, sep=',', index=False)

    split_out = pd.DataFrame({'Split read start': parse_summary(args.split, ss_fields, events_df, run_id, args.time)})
    split_out.to_csv(args.split_out, sep=',', index=False)

    internal_out = pd.DataFrame({'Internal read start': parse_summary(args.internal, ss_fields, events_df, run_id, args.time)})
    internal_out.to_csv(args.internal_out, sep=',', index=False)
    all_out = args.event + '.csv'
    events_df.to_csv(all_out, sep=',', index=False)

    """
    This script is flawed because it counts unblocks multiple times if
    they are overlapping; i.e if an unblock is within N seconds of > 1
    read start it will be counted for every read start
    """
    """
    CAN THIS BE USED TO IDENTIFY UNBLOCKS THAT END READS AND UNBLOCKS THAT DO NOT END READS... 
    """
    return


def parse_summary(summary_file, fields, state_df, run_id, time):
    sum_df = pd.read_csv(summary_file, sep='\t', usecols=fields)
    # parse summary file to only this run
    sum_df = sum_df[sum_df['run_id'] == run_id]
    # create df cols for before and after times
    sum_df['before'] = sum_df['start_time'] - time
    sum_df['after'] = sum_df['start_time'] + time
    vals = np.ndarray([])
    for index, row in sum_df.iterrows():
        vals = np.append(
            vals,
            (state_df[state_df['acquisition_raw_index'].between(
                row['before'],
                row['after'],
                inclusive=True
            )]['acquisition_raw_index'] - row['start_time']).values
        )
    return vals


def get_dtypes(path, field):
    return h5py.check_dtype(enum=path.dtype[field])


def get_df(path, fields):
    data_labels = {}
    for field in fields:
        data_labels[field] = path[field]
    labels_df = pd.DataFrame(data=data_labels)
    return labels_df


def get_args():
    parser = ArgumentParser(
        description="""Find all the occurrences of a given event across an entire bulkfile""",
        add_help=False)
    general = parser.add_argument_group(
        title='General options')
    general.add_argument("-h", "--help",
                         action="help",
                         help="Show this help and exit"
                         )
    in_args = parser.add_argument_group(
        title='Input sources'
    )
    in_args.add_argument("-b", "--bulk-file",
                         help="A bulk-fast5 file generated by MinKNOW",
                         type=str,
                         default="",
                         required=True,
                         metavar=''
                         )
    in_args.add_argument("-T", "--split",
                         help="A sequencing summary file of true reads that are incorrectly split by MinKNOW",
                         type=str,
                         default='',
                         required=True,
                         metavar=''
                         )
    in_args.add_argument("-I", "--internal",
                         help="A sequencing summary file of read starts from incorrect splits",
                         type=str,
                         default='',
                         required=True,
                         metavar=''
                         )
    in_args.add_argument("-S", "--singles",
                         help="A sequencing summary file of correctly split reads",
                         type=str,
                         default='',
                         required=True,
                         metavar=''
                         )
    in_args.add_argument("-e", "--event",
                         help="The event, from \'StateData\', to find. Defaults to \'unblocking\'.",
                         type=str,
                         default='unblocking',
                         required=False,
                         metavar=''
                         )
    in_args.add_argument("-t", "--time",
                         help='Sample time around a read start in seconds. Defaults to 5 seconds''',
                         type=int,
                         required=True,
                         default=5,
                         metavar=''
                         )
    out_args = parser.add_argument_group(
        title='Output files'
    )
    out_args.add_argument("-o", "--output",
                          help='Name of CSV file where output is written''',
                          type=str,
                          default='output.csv',
                          metavar=''
                          )
    out_args.add_argument("-1", "--split-out",
                          help='Name CSV file where split output is written''',
                          type=str,
                          default='split.csv',
                          metavar=''
                          )
    out_args.add_argument("-2", "--internal-out",
                          help='Name CSV file where internal output is written''',
                          type=str,
                          default='internal.csv',
                          metavar=''
                          )
    out_args.add_argument("-3", "--singles-out",
                          help='Name CSV file where singles output is written''',
                          type=str,
                          default='singles.csv',
                          metavar=''
                          )
    return parser.parse_args()


if __name__ == '__main__':
    main()
