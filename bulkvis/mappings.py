import pandas as pd
import numpy as np
from readpaf import parse_paf
import gzip

# from argparse import ArgumentParser
from pathlib import Path


def run(parser, args):
    # Open [PAF] mapping file with specified columns
    if args.paf.endswith(".gz"):
        fopen = gzip.open
    else:
        fopen = open
    with fopen(args.paf, "rt") as fh:
        pf = parse_paf(fh, dataframe=True)
    # Thin PAF file by 'Primary alignment type' and drop duplicates
    pf = pf[pf["tp"].eq("P")]
    pf = pf.sort_values(
        ["query_name", "target_name", "mapping_quality"], ascending=[True, True, False]
    )
    # col_names = [
    #     "Qname",
    #     "Strand",
    #     "Tname",
    #     "Tstart",
    #     "Tend",
    #     "mapping_quality",
    #     "alignment_type",
    # ]
    # pf = pd.read_csv(
    #     paf_path,
    #     sep="\t",
    #     header=None,
    #     names=col_names,
    #     usecols=[0, 4, 5, 7, 8, 11, 12],
    # )
    pf = pf.drop_duplicates(["query_name"], keep="first")
    # Open sequencing_summary.txt file
    cols = ["read_id", "run_id", "channel", "start_time", "duration"]
    ss = pd.read_csv(args.summary, sep="\t", usecols=cols)
    # Merge seq_sum and paf files
    df = pd.merge(ss, pf, left_on="read_id", right_on="query_name", how="outer")
    df = df.dropna()

    df["end_time"] = df["start_time"] + df["duration"]
    df["start_mapping"] = (
        df[["target_start", "target_end"]]
        .min(axis=1)
        .astype("int64")
        .map("{0:,d}".format)
    )
    df["end_mapping"] = (
        df[["target_start", "target_end"]]
        .max(axis=1)
        .astype("int64")
        .map("{0:,d}".format)
    )
    df["label"] = (
        df["target_name"].astype("str")
        + ": "
        + df["start_mapping"].astype("str")
        + " - "
        + df["end_mapping"].astype("str")
    )

    # df = df.rename(columns={"Tname": "target_name", "Strand": "strand"})
    # export as <run_id>.bmf
    header = [
        "run_id",
        "read_id",
        "channel",
        "start_time",
        "end_time",
        "target_name",
        "strand",
        "start_mapping",
        "end_mapping",
        "label",
    ]
    i = 0
    for k, v in df.groupby(["run_id"]):
        # Join 'bmf' path, run_id, and file extension
        p = Path(args.bmf).joinpath(str(k) + ".bmf")
        v.to_csv(p, sep="\t", header=True, columns=header, index=False)
        i += 1

    print("{n} files written to {p}".format(n=i, p=args.bmf))


def full_path(file):
    return str(Path(file).expanduser().resolve())


_help = """Parse sequencing_summary.txt files and .paf files to format mapping info for bulkvis"""
_cli = (
    (
        "-s",
        "--summary",
        dict(
            help="A sequencing summary file generated by albacore or guppy",
            type=full_path,
            default="",
            required=True,
            metavar="",
        ),
    ),
    (
        "-p",
        "--paf",
        dict(
            help="A paf file generated by minimap2",
            type=full_path,
            default="",
            required=True,
            metavar="",
        ),
    ),
    (
        "--bmf",
        dict(
            help="Specify the output folder, where files will be written as "
            "<run_id>.bmf. This should be the same folder as the bulk FAST5 "
            "file for this experiment.",
            type=full_path,
            metavar="",
            required=True,
        ),
    ),
)
