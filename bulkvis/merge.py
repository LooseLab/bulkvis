"""merge.py
"""
from bulkvis.core import die, fuse_reads, concat_files_to_df, find_files_of_type
import pandas as pd
from pathlib import Path
from tqdm import tqdm


_help = """Merge FASTQ files based on a fused_reads.txt or ONT 
sequencing_summary.txt and minimap2 .paf files"""
_cli = (
    (
        "-d",
        "--distance",
        dict(
            help="Specify the maximum distance between consecutive mappings, only used with "
            "--summary and --paf options",
            type=int,
            default=10000,
        ),
    ),
    (
        # The behaviour of 'alt' is confusing... it seems like a double negative
        "-a",
        "--alt",
        dict(
            help="""Exclude alternate assemblies""", action="store_false", default=True
        ),
    ),
    (
        "-s",
        "--summary",
        dict(
            help="Sequencing summary file(s) generated by albacore or guppy", nargs="+",
        ),
    ),
    (
        "-p",
        "--paf",
        dict(help="paf file(s) generated by minimap2", metavar="", nargs="+"),
    ),
    (
        "--fused-reads",
        dict(help="fused_reads.txt file generated by `bulkvis fuse`", metavar=""),
    ),
    (
        "-i",
        "--input",
        dict(
            help="FASTQ files or directories of input, if a directory is given files with extension"
            "'.fastq' or '.fq' will be used",
            nargs="+",
        ),
    ),
    (
        "-o",
        "--output-dir",
        dict(
            help="Reads will be grouped as fused or un-fused. Fused reads will be saved "
            "in this directory. If not set uses current working directory",
        ),
    ),
    (
        "--format",
        dict(
            help="Output format for the reads",
            default="fastq",
            choices=["fastq", "fasta"],
        ),
    ),
    (
        "--all-reads",
        dict(
            help="Write un-fused reads to 'un_fused_reads.fastq' in the output directory",
            action="store_true",
        ),
    ),
)


# TODO: Simplify, remove summary/paf -> require fused_reads.txt
def run(parser, args):
    """Find fused reads and merge fasta/q"""

    """
    Minimum required files for this script to operate:
     - sequencing_summary.txt AND mapping.paf
     OR
     - fused_reads.txt

    If both sets are provided, raise exception or if one or the other provided

    This code block will provide fused_read_ids and fused_reads_tuples
    """
    if args.fused_reads and not (args.summary or args.paf):
        # Open fused_reads.txt file
        fused_df = pd.read_csv(args.fused_reads, sep='\t', usecols=['run_id', 'cat_read_id', 'count'])
        # Set fused_read_tuples and fused_read_ids_flat
        fused_read_tuples = fused_df['cat_read_id'].str.split('|').tolist()
        fused_read_ids = [item for sublist in fused_read_tuples for item in sublist]
    elif args.summary and args.paf and not args.fused_reads:
        # Open sequencing_summary file and paf file, and run bulkvis.fuse_reads
        seq_sum_df = concat_files_to_df(file_list=args.summary,
                                        sep='\t',
                                        usecols=['channel', 'start_time', 'duration',
                                                 'run_id', 'read_id', 'sequence_length_template',
                                                 'filename']
                                        )
        # Open minimap2 paf files into a single pd.DataFrame
        paf_df = concat_files_to_df(file_list=args.paf,
                                    sep='\t',
                                    header=None,
                                    usecols=[0, 4, 5, 7, 8],
                                    names=['Qname', 'Strand', 'Tname', 'Tstart', 'Tend']
                                    )
        fused_df, un_fused_df, to_be_fused_df = fuse_reads(seq_sum_df, paf_df, distance=args.distance, alt=False)
        fused_read_tuples = fused_df['cat_read_id'].str.split('|').tolist()
        fused_read_ids = to_be_fused_df['read_id'].tolist()
    else:
        # Raise a parser error
        parser.error('Either a fused_reads.txt, from bulkvis fuse OR sequencing_summary.txt '
                     'and .paf files must be provided.')

    # Empty list for fastq file paths
    fastq_files = []
    # TODO: Maybe consider gzip support
    # These should be lowercase and include the '.'
    endings = ['.fastq', '.fq']

    for file_or_directory in args.input:
        fastq_files.extend(find_files_of_type(file_or_directory, endings))
    # remove none from fastq_files
    fastq_files = list(filter(None.__ne__, fastq_files))

    # End if no fastq files are found
    if not fastq_files:
        die('No FASTQ files found', status=0)

    print('{} fastq files found'.format(len(fastq_files)))
    # Create a read dictionary to hold all the fused reads that are found
    reads = {}
    # Run loop over fastq_files, opening each file and adding only reads that are fused to the dictionary.
    for fastq_file in tqdm(fastq_files, desc='FASTQ processed'):
        # with open(fastq_file, 'r') as fastq:
        with fastq_file.open('r') as fastq:
            for line in fastq:
                header = line.strip()[1:]
                read_id = header.split()[0]
                if read_id in fused_read_ids:
                    sequence = next(fastq).strip()
                    next(fastq)
                    qualities = next(fastq).strip()
                    reads[read_id] = {
                        'header': header.split(),
                        'sequence': sequence,
                        'qualities': qualities
                    }
                else:
                    next(fastq)
                    next(fastq)
                    next(fastq)

    if args.output_dir is not None:
        Path(args.output_dir).mkdir(parents=True, exist_ok=True)
        p = Path(args.output_dir)
    else:
        print('No output directory specified, using current working directory')
        p = Path('.')
    # Set format and create folders for output
    if args.format == 'fastq':
        fused_read_file = p / 'fused_reads.fastq'
    else:
        fused_read_file = p / 'fused_reads.fasta'

    # Split out fused reads into new file
    write_counter = 0
    miss_counter = 0
    # with open(fused_read_file, 'w') as output_fused:
    with fused_read_file.open('w') as output_fused:
        for pair in tqdm(fused_read_tuples, desc='Fused reads written'):
            if _read_id_not_in_dict(pair, reads):
                miss_counter += 1
                continue
            if args.format == 'fastq':
                read_str = '@{read_id} {run_id} {number}\n{seq}\n+\n{qual}\n'.format(
                    read_id='|'.join(pair),
                    run_id=reads[pair[0]]['header'][1],
                    number=reads[pair[0]]['header'][2],
                    seq=''.join([reads[s]['sequence'] for s in pair]),
                    qual=''.join([reads[s]['qualities'] for s in pair])
                )
            else:  # fasta
                read_str = '>{read_id} {run_id} {number}\n{seq}\n'.format(
                    read_id='|'.join(pair),
                    run_id=reads[pair[0]]['header'][1],
                    number=reads[pair[0]]['header'][2],
                    seq=''.join([reads[s]['sequence'] for s in pair])
                )
            output_fused.write(read_str)
            write_counter += 1

    print('{} fused reads written'.format(write_counter))
    if miss_counter > 0:
        print('{} fused reads missed. These reads are most likely in the "fail" folder.'.format(miss_counter))

    # This will return if write all is not set,
    if not args.all_reads:
        die('', status=0)

    print('Writing un-fused reads')

    # Set path the output directory and make any missing folders
    if args.format == 'fastq':
        un_fused_read_file = p / 'un_fused_reads.fastq'
    else:
        un_fused_read_file = p / 'un_fused_reads.fasta'

    # Set new write counter
    write_counter = 0
    # with open(un_fused_read_file, 'w') as output_un_fused:
    with un_fused_read_file.open('w') as output_un_fused:
        for file in tqdm(fastq_files, desc='FASTQ processed'):
            # with open(file, 'r') as fastq:
            with file.open('r') as fastq:
                for line in fastq:
                    header = line.strip()[1:]
                    read_id = header.split()[0]
                    if read_id not in fused_read_ids:
                        sequence = next(fastq).strip()
                        next(fastq)
                        qualities = next(fastq).strip()
                        # Write the read out
                        if args.format == 'fastq':
                            read_str = '@{header}\n{seq}\n+\n{qual}\n'.format(
                                header=header,
                                seq=sequence,
                                qual=qualities
                            )
                        else:  # fasta
                            read_str = '>{header}\n{seq}\n'.format(
                                header=header,
                                seq=sequence
                            )
                        output_un_fused.write(read_str)
                        write_counter += 1
                    else:
                        next(fastq)
                        next(fastq)
                        next(fastq)
    print('{} un-fused reads written'.format(write_counter))
    # TODO: Read and write FASTA, FASTQ, and gzip
    # TODO: Improve arguments, add required inputs


def _read_id_not_in_dict(read_ids, read_dict):
    """Return True if all read_ids in a list are not in the read_dict keys, otherwise False"""
    for read_id in read_ids:
        if read_id not in read_dict.keys():
            return True
    return False
